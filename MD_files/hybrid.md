# SfM Quality-Based Hybrid Adaptive Sampling

## ê°œìš”

ê¸°ì¡´ Geometry ê¸°ë°˜ adaptive samplingì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•œ **SfM í’ˆì§ˆ ê¸°ë°˜ Hybrid ì ‘ê·¼ë²•** êµ¬í˜„ ê³„íšì„œì…ë‹ˆë‹¤.

### ì—°êµ¬ Contribution

**Contribution 1**: ê°™ì€ í”„ë ˆì„ ìˆ˜ë¡œ ë” ì¢‹ì€ í’ˆì§ˆ
> "ê°™ì€ Nì¥ì´ë¼ë„ **ì–´ë–¤ í”„ë ˆì„**ì„ ë½‘ëŠëƒì— ë”°ë¼ SfM/3DGS í’ˆì§ˆì´ ë‹¬ë¼ì§„ë‹¤"

**Contribution 2**: ìµœì†Œ í”„ë ˆì„ ì¶”ê°€ë¡œ ìµœëŒ€ íš¨ê³¼  
> "fps 2â†’3 (1.5ë°° ì¦ê°€) ì „ì²´ ì¶”ê°€ë³´ë‹¤, **ì„ íƒì  ì†ŒëŸ‰ ì¶”ê°€**ê°€ ë” íš¨ìœ¨ì ì´ë‹¤"

---

## ê¸°ì¡´ ë°©ì‹ì˜ ë¬¸ì œì 

### í˜„ì¬ êµ¬í˜„ (Geometry ê¸°ë°˜)
```
Pass 1: Uniform fpsë¡œ Nì¥ ì¶”ì¶œ â†’ COLMAP
Pass 2: ì¹´ë©”ë¼ pose ë¶„ì„ â†’ ê· ë“±í•œ physical spacingìœ¼ë¡œ í”„ë ˆì„ ì¬ì„ íƒ
```

### ë¬¸ì œì 

| ë¬¸ì œ | ì„¤ëª… |
|------|------|
| **ê°™ì€ í”„ë ˆì„ í’€** | Pass 2ì—ì„œ ì„ íƒí•˜ëŠ” í”„ë ˆì„ì´ Pass 1ì˜ ë¶€ë¶„ì§‘í•© |
| **ìƒˆë¡œìš´ ì •ë³´ ì—†ìŒ** | ê¸°ì¡´ í”„ë ˆì„ì„ ì†ì•„ë‚´ëŠ” ê²ƒì´ì§€ ì¶”ê°€ê°€ ì•„ë‹˜ |
| **SfM í’ˆì§ˆ ë¬´ì‹œ** | ì‹¤ì œ SfM ê¸°ì—¬ë„ì™€ ë¬´ê´€í•˜ê²Œ geometryë§Œ ê³ ë ¤ |

### ì‹¤í—˜ ê²°ê³¼ (í˜„ì¬)
```
Original (uniform fps=2):  18.2k points, PSNR 30.81 (30K iter)
Adaptive (Î±=0.5, Î²=0.5):   17.88k points, PSNR 30.59 (30K iter)
```
â†’ SfM points ê°ì†Œ, PSNR í•˜ë½

---

## ìƒˆë¡œìš´ ì ‘ê·¼ë²•: SfM Quality-Based Hybrid Sampling

### í•µì‹¬ ì•„ì´ë””ì–´

1. **ê¸°ì—¬ë„ ë‚®ì€ ì´ë¯¸ì§€ ì‹ë³„**: COLMAP ê²°ê³¼ì—ì„œ ê° ì´ë¯¸ì§€ì˜ SfM ê¸°ì—¬ë„ ì¸¡ì •
2. **Hybrid Gap Priority**: Geometry + Feature Track ì—°ì†ì„± ê²°í•©
3. **í”„ë ˆì„ êµì²´**: ê¸°ì—¬ë„ ë‚®ì€ í”„ë ˆì„ì„ ë†’ì€ priority gapì˜ ìƒˆ timestampë¡œ êµì²´

### ì „ì²´ íŒŒì´í”„ë¼ì¸

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 1: ì´ˆê¸° ì¶”ì¶œ ë° SfM                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Uniform fps=2ë¡œ Nì¥ ì¶”ì¶œ                                      â”‚
â”‚  2. COLMAP ì‹¤í–‰ â†’ images.txt, points3D.txt ìƒì„±                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 2: SfM í’ˆì§ˆ ë¶„ì„                                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  3. ê° ì´ë¯¸ì§€ì˜ SfM ê¸°ì—¬ë„(valid_observations) ê³„ì‚°               â”‚
â”‚  4. ì¸ì ‘ ì´ë¯¸ì§€ ê°„ Feature Track ì—°ì†ì„± ê³„ì‚°                       â”‚
â”‚  5. ì¹´ë©”ë¼ ê°„ Geometry ê±°ë¦¬ ê³„ì‚° (ê¸°ì¡´ êµ¬í˜„ í™œìš©)                   â”‚
â”‚  6. Hybrid Gap Priority Score ê³„ì‚°                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 3: í”„ë ˆì„ êµì²´                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  7. ê¸°ì—¬ë„ í•˜ìœ„ Kì¥ ì„ íƒ (êµì²´ ëŒ€ìƒ)                               â”‚
â”‚  8. Gap Priority ìƒìœ„ Kê°œ êµ¬ê°„ ì„ íƒ (ì‚½ì… ìœ„ì¹˜)                    â”‚
â”‚  9. ìƒˆ timestamp ê³„ì‚° (gap ì¤‘ê°„ ì§€ì )                             â”‚
â”‚  10. ì›ë³¸ ë¹„ë””ì˜¤ì—ì„œ ìƒˆ í”„ë ˆì„ ì¶”ì¶œ                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 4: ì¬êµ¬ì„± ë° ê²€ì¦                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  11. ìƒˆ í”„ë ˆì„ ì„¸íŠ¸ë¡œ COLMAP ì¬ì‹¤í–‰                               â”‚
â”‚  12. SfM points ìˆ˜ ë¹„êµ                                          â”‚
â”‚  13. 3DGS í•™ìŠµ ë° PSNR í‰ê°€                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## êµ¬í˜„ ìƒì„¸

### 1. SfM ê¸°ì—¬ë„ ê³„ì‚° ëª¨ë“ˆ

**íŒŒì¼**: `sfm_quality_analyzer.py` (ì‹ ê·œ ìƒì„±)

```python
"""
SfM Quality Analyzer

COLMAP ì¶œë ¥ì„ ë¶„ì„í•˜ì—¬ ê° ì´ë¯¸ì§€ì˜ SfM ê¸°ì—¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
"""

from typing import Dict, List, Tuple, Set
from dataclasses import dataclass
from pathlib import Path
import numpy as np


@dataclass
class ImageContribution:
    """ì´ë¯¸ì§€ì˜ SfM ê¸°ì—¬ë„ ì •ë³´"""
    image_id: int
    image_name: str
    timestamp: float
    
    # ê¸°ì—¬ë„ ì§€í‘œ
    total_observations: int      # ì „ì²´ 2D point ìˆ˜
    valid_observations: int      # ìœ íš¨í•œ 3D point ê´€ì¸¡ ìˆ˜ (POINT3D_ID != -1)
    
    # ì¶”ê°€ ë¶„ì„ìš© (ì„ íƒì )
    observed_point3d_ids: Set[int]  # ê´€ì¸¡í•œ 3D point ID ì§‘í•©
    
    @property
    def contribution_score(self) -> float:
        """ê¸°ë³¸ ê¸°ì—¬ë„ ì ìˆ˜ = valid_observations"""
        return float(self.valid_observations)
    
    @property
    def observation_ratio(self) -> float:
        """ìœ íš¨ ê´€ì¸¡ ë¹„ìœ¨"""
        if self.total_observations == 0:
            return 0.0
        return self.valid_observations / self.total_observations


@dataclass  
class FeatureTrackContinuity:
    """ì¸ì ‘ ì´ë¯¸ì§€ ê°„ Feature Track ì—°ì†ì„±"""
    image_i_id: int
    image_j_id: int
    timestamp_i: float
    timestamp_j: float
    
    shared_point_count: int      # ê³µìœ í•˜ëŠ” 3D point ìˆ˜
    continuity_score: float      # ì •ê·œí™”ëœ ì—°ì†ì„± ì ìˆ˜


class SfMQualityAnalyzer:
    """SfM í’ˆì§ˆ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, colmap_dir: str):
        """
        Args:
            colmap_dir: COLMAP sparse reconstruction ë””ë ‰í† ë¦¬ ê²½ë¡œ
                       (ë³´í†µ <dataset>/sparse/0/)
        """
        self.colmap_dir = Path(colmap_dir)
        self.images_file = self.colmap_dir / "images.txt"
        self.points3d_file = self.colmap_dir / "points3D.txt"
        
    def parse_images_with_observations(self) -> Dict[int, ImageContribution]:
        """
        images.txtë¥¼ íŒŒì‹±í•˜ì—¬ ê° ì´ë¯¸ì§€ì˜ ê¸°ì—¬ë„ ì •ë³´ë¥¼ ì¶”ì¶œ
        
        Returns:
            image_idë¥¼ keyë¡œ í•˜ëŠ” ImageContribution ë”•ì…”ë„ˆë¦¬
        """
        contributions = {}
        
        with open(self.images_file, 'r') as f:
            lines = f.readlines()
        
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            
            if not line or line.startswith('#'):
                i += 1
                continue
            
            # ì²«ì§¸ ì¤„: IMAGE_ID QW QX QY QZ TX TY TZ CAMERA_ID NAME
            parts = line.split()
            if len(parts) < 10:
                i += 1
                continue
            
            try:
                image_id = int(parts[0])
                image_name = parts[9]
                
                # íŒŒì¼ëª…ì—ì„œ timestamp ì¶”ì¶œ (ê¸°ì¡´ colmap_parser ë¡œì§ í™œìš©)
                timestamp = self._extract_timestamp(image_name)
                
                # ë‘˜ì§¸ ì¤„: POINTS2D[] as (X, Y, POINT3D_ID) ...
                i += 1
                if i >= len(lines):
                    break
                    
                points_line = lines[i].strip()
                point3d_ids = self._parse_point3d_ids(points_line)
                
                # ìœ íš¨í•œ ê´€ì¸¡ ê³„ì‚°
                valid_ids = [pid for pid in point3d_ids if pid != -1]
                
                contributions[image_id] = ImageContribution(
                    image_id=image_id,
                    image_name=image_name,
                    timestamp=timestamp,
                    total_observations=len(point3d_ids),
                    valid_observations=len(valid_ids),
                    observed_point3d_ids=set(valid_ids)
                )
                
            except (ValueError, IndexError) as e:
                print(f"Warning: Failed to parse line {i}: {e}")
            
            i += 1
        
        return contributions
    
    def _parse_point3d_ids(self, points_line: str) -> List[int]:
        """
        POINTS2D ë¼ì¸ì—ì„œ POINT3D_IDë“¤ì„ ì¶”ì¶œ
        
        Format: X1 Y1 POINT3D_ID1 X2 Y2 POINT3D_ID2 ...
        """
        if not points_line:
            return []
            
        parts = points_line.split()
        point3d_ids = []
        
        # 3ê°œì”© ë¬¶ì–´ì„œ ì²˜ë¦¬ (X, Y, POINT3D_ID)
        for j in range(2, len(parts), 3):
            try:
                point3d_id = int(parts[j])
                point3d_ids.append(point3d_id)
            except (ValueError, IndexError):
                continue
        
        return point3d_ids
    
    def _extract_timestamp(self, filename: str, fps: float = 2.0) -> float:
        """íŒŒì¼ëª…ì—ì„œ timestamp ì¶”ì¶œ"""
        import re
        
        # frame_NNNNNN.ext íŒ¨í„´
        match = re.search(r'frame_(\d+)', filename)
        if match:
            frame_number = int(match.group(1))
            return frame_number / fps
        
        # NNNNNN.ext íŒ¨í„´
        match = re.search(r'(\d+)\.', filename)
        if match:
            frame_number = int(match.group(1))
            return frame_number / fps
        
        return 0.0
    
    def compute_feature_track_continuity(
        self,
        contributions: Dict[int, ImageContribution]
    ) -> List[FeatureTrackContinuity]:
        """
        ì¸ì ‘ ì´ë¯¸ì§€ ê°„ì˜ Feature Track ì—°ì†ì„± ê³„ì‚°
        
        Args:
            contributions: parse_images_with_observations() ê²°ê³¼
            
        Returns:
            ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬ëœ FeatureTrackContinuity ë¦¬ìŠ¤íŠ¸
        """
        # timestamp ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_images = sorted(
            contributions.values(),
            key=lambda x: x.timestamp
        )
        
        continuities = []
        
        for idx in range(len(sorted_images) - 1):
            img_i = sorted_images[idx]
            img_j = sorted_images[idx + 1]
            
            # ê³µìœ í•˜ëŠ” 3D point ê³„ì‚°
            shared_points = img_i.observed_point3d_ids & img_j.observed_point3d_ids
            shared_count = len(shared_points)
            
            # ì—°ì†ì„± ì ìˆ˜ = ê³µìœ  point ìˆ˜ / min(ë‘ ì´ë¯¸ì§€ì˜ valid observations)
            min_observations = min(img_i.valid_observations, img_j.valid_observations)
            if min_observations > 0:
                continuity_score = shared_count / min_observations
            else:
                continuity_score = 0.0
            
            continuities.append(FeatureTrackContinuity(
                image_i_id=img_i.image_id,
                image_j_id=img_j.image_id,
                timestamp_i=img_i.timestamp,
                timestamp_j=img_j.timestamp,
                shared_point_count=shared_count,
                continuity_score=continuity_score
            ))
        
        return continuities
    
    def select_low_contribution_images(
        self,
        contributions: Dict[int, ImageContribution],
        bottom_ratio: float = 0.2
    ) -> List[ImageContribution]:
        """
        ê¸°ì—¬ë„ í•˜ìœ„ Kì¥ ì„ íƒ
        
        Args:
            contributions: ì´ë¯¸ì§€ ê¸°ì—¬ë„ ë”•ì…”ë„ˆë¦¬
            bottom_ratio: í•˜ìœ„ ë¹„ìœ¨ (0.2 = í•˜ìœ„ 20%)
            
        Returns:
            ê¸°ì—¬ë„ ë‚®ì€ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ (ê¸°ì—¬ë„ ì˜¤ë¦„ì°¨ìˆœ)
        """
        sorted_images = sorted(
            contributions.values(),
            key=lambda x: x.contribution_score
        )
        
        k = int(len(sorted_images) * bottom_ratio)
        k = max(1, k)  # ìµœì†Œ 1ê°œ
        
        return sorted_images[:k]
    
    def get_statistics(
        self,
        contributions: Dict[int, ImageContribution]
    ) -> dict:
        """ê¸°ì—¬ë„ í†µê³„ ì •ë³´"""
        scores = [c.contribution_score for c in contributions.values()]
        ratios = [c.observation_ratio for c in contributions.values()]
        
        return {
            'num_images': len(contributions),
            'contribution': {
                'mean': np.mean(scores),
                'std': np.std(scores),
                'min': np.min(scores),
                'max': np.max(scores),
                'median': np.median(scores),
            },
            'observation_ratio': {
                'mean': np.mean(ratios),
                'std': np.std(ratios),
                'min': np.min(ratios),
                'max': np.max(ratios),
            }
        }
```

---

### 2. Hybrid Gap Priority Calculator

**íŒŒì¼**: `hybrid_gap_analyzer.py` (ì‹ ê·œ ìƒì„±)

```python
"""
Hybrid Gap Analyzer

Geometryì™€ Feature Track ì—°ì†ì„±ì„ ê²°í•©í•œ Gap Priority ê³„ì‚°
"""

from typing import List, Tuple
from dataclasses import dataclass
import numpy as np

from sfm_quality_analyzer import FeatureTrackContinuity
from trajectory_analyzer import TrajectorySegment


@dataclass
class HybridGap:
    """Hybrid ë¶„ì„ ê¸°ë°˜ Gap ì •ë³´"""
    start_timestamp: float
    end_timestamp: float
    
    # Geometry ì •ë³´ (ê¸°ì¡´ TrajectorySegmentì—ì„œ)
    camera_distance: float       # ì¹´ë©”ë¼ ê°„ ë¬¼ë¦¬ì  ê±°ë¦¬
    geometry_score: float        # ì •ê·œí™”ëœ geometry score
    
    # Feature Track ì •ë³´
    shared_features: int         # ê³µìœ  feature ìˆ˜
    continuity_score: float      # ì •ê·œí™”ëœ ì—°ì†ì„± (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
    
    # Hybrid Priority
    gap_priority: float          # ìµœì¢… priority (ë†’ì„ìˆ˜ë¡ í”„ë ˆì„ í•„ìš”)
    
    @property
    def midpoint_timestamp(self) -> float:
        """Gap ì¤‘ê°„ ì§€ì  timestamp"""
        return (self.start_timestamp + self.end_timestamp) / 2


class HybridGapAnalyzer:
    """Hybrid Gap Priority ë¶„ì„ê¸°"""
    
    def __init__(
        self,
        geometry_weight: float = 0.5,
        continuity_weight: float = 0.5
    ):
        """
        Args:
            geometry_weight: Geometry score ê°€ì¤‘ì¹˜
            continuity_weight: Continuity score ê°€ì¤‘ì¹˜ (ì—­ìˆ˜ë¡œ ì‚¬ìš©ë¨)
        """
        self.geometry_weight = geometry_weight
        self.continuity_weight = continuity_weight
    
    def compute_hybrid_gaps(
        self,
        segments: List[TrajectorySegment],
        continuities: List[FeatureTrackContinuity]
    ) -> List[HybridGap]:
        """
        Geometryì™€ Feature Track ì •ë³´ë¥¼ ê²°í•©í•œ Hybrid Gap ê³„ì‚°
        
        Args:
            segments: TrajectoryAnalyzerì˜ ì¶œë ¥
            continuities: SfMQualityAnalyzerì˜ Feature Track ì—°ì†ì„± ì¶œë ¥
            
        Returns:
            HybridGap ë¦¬ìŠ¤íŠ¸ (ì‹œê°„ìˆœ)
        """
        if len(segments) != len(continuities):
            raise ValueError(
                f"Segment count ({len(segments)}) != Continuity count ({len(continuities)})"
            )
        
        # Geometry ì •ê·œí™”ë¥¼ ìœ„í•œ í†µê³„
        geo_scores = [seg.score for seg in segments]
        geo_mean = np.mean(geo_scores)
        geo_std = np.std(geo_scores) + 1e-6
        
        # Continuity ì •ê·œí™”ë¥¼ ìœ„í•œ í†µê³„
        cont_scores = [c.continuity_score for c in continuities]
        cont_mean = np.mean(cont_scores)
        cont_std = np.std(cont_scores) + 1e-6
        
        hybrid_gaps = []
        
        for seg, cont in zip(segments, continuities):
            # ì •ê·œí™”ëœ Geometry score (ë†’ì„ìˆ˜ë¡ ì¹´ë©”ë¼ ë§ì´ ì›€ì§ì„)
            norm_geo = (seg.score - geo_mean) / geo_std
            
            # ì •ê·œí™”ëœ Continuity score (ë‚®ì„ìˆ˜ë¡ feature ì—°ê²° ì•½í•¨)
            norm_cont = (cont.continuity_score - cont_mean) / cont_std
            
            # Gap Priority = geometry ë†’ê³  + continuity ë‚®ìœ¼ë©´ ë†’ìŒ
            # continuityëŠ” ì—­ìˆ˜ ê°œë…ìœ¼ë¡œ ì‚¬ìš© (ë‚®ì„ìˆ˜ë¡ ë³´ê°• í•„ìš”)
            gap_priority = (
                self.geometry_weight * norm_geo - 
                self.continuity_weight * norm_cont
            )
            
            hybrid_gaps.append(HybridGap(
                start_timestamp=seg.start_pose.timestamp,
                end_timestamp=seg.end_pose.timestamp,
                camera_distance=seg.translation_distance,
                geometry_score=seg.score,
                shared_features=cont.shared_point_count,
                continuity_score=cont.continuity_score,
                gap_priority=gap_priority
            ))
        
        return hybrid_gaps
    
    def select_high_priority_gaps(
        self,
        gaps: List[HybridGap],
        top_k: int
    ) -> List[HybridGap]:
        """
        Priorityê°€ ë†’ì€ ìƒìœ„ Kê°œ gap ì„ íƒ
        
        Args:
            gaps: HybridGap ë¦¬ìŠ¤íŠ¸
            top_k: ì„ íƒí•  gap ìˆ˜
            
        Returns:
            Priority ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬ëœ ìƒìœ„ Kê°œ gap
        """
        sorted_gaps = sorted(gaps, key=lambda g: g.gap_priority, reverse=True)
        return sorted_gaps[:top_k]
    
    def filter_textureless_gaps(
        self,
        gaps: List[HybridGap],
        min_features_threshold: int = 50
    ) -> List[HybridGap]:
        """
        Textureless êµ¬ê°„ í•„í„°ë§
        
        Feature ìˆ˜ê°€ ë„ˆë¬´ ì ì€ êµ¬ê°„ì€ í”„ë ˆì„ì„ ì¶”ê°€í•´ë„ íš¨ê³¼ ì—†ìŒ
        
        Args:
            gaps: HybridGap ë¦¬ìŠ¤íŠ¸
            min_features_threshold: ìµœì†Œ ê³µìœ  feature ìˆ˜
            
        Returns:
            Texturelessê°€ ì•„ë‹Œ gapë§Œ í•„í„°ë§
        """
        return [
            gap for gap in gaps 
            if gap.shared_features >= min_features_threshold
        ]
    
    def get_statistics(self, gaps: List[HybridGap]) -> dict:
        """Gap í†µê³„ ì •ë³´"""
        priorities = [g.gap_priority for g in gaps]
        distances = [g.camera_distance for g in gaps]
        continuities = [g.continuity_score for g in gaps]
        features = [g.shared_features for g in gaps]
        
        return {
            'num_gaps': len(gaps),
            'priority': {
                'mean': np.mean(priorities),
                'std': np.std(priorities),
                'min': np.min(priorities),
                'max': np.max(priorities),
            },
            'camera_distance': {
                'mean': np.mean(distances),
                'std': np.std(distances),
            },
            'continuity': {
                'mean': np.mean(continuities),
                'std': np.std(continuities),
            },
            'shared_features': {
                'mean': np.mean(features),
                'min': np.min(features),
                'max': np.max(features),
            }
        }
```

---

### 3. í”„ë ˆì„ êµì²´ ë¡œì§

**íŒŒì¼**: `frame_replacer.py` (ì‹ ê·œ ìƒì„±)

```python
"""
Frame Replacer

ê¸°ì—¬ë„ ë‚®ì€ í”„ë ˆì„ì„ ë†’ì€ priority gapì˜ ìƒˆ timestampë¡œ êµì²´
"""

from typing import List, Tuple, Set
from dataclasses import dataclass
import numpy as np

from sfm_quality_analyzer import ImageContribution
from hybrid_gap_analyzer import HybridGap


@dataclass
class FrameReplacement:
    """í”„ë ˆì„ êµì²´ ì •ë³´"""
    # ì œê±°í•  í”„ë ˆì„
    remove_timestamp: float
    remove_image_name: str
    remove_contribution: float
    
    # ì¶”ê°€í•  í”„ë ˆì„
    new_timestamp: float
    target_gap: HybridGap
    
    # êµì²´ ê·¼ê±°
    reason: str


class FrameReplacer:
    """í”„ë ˆì„ êµì²´ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, video_fps: float = 30.0):
        """
        Args:
            video_fps: ì›ë³¸ ë¹„ë””ì˜¤ fps
        """
        self.video_fps = video_fps
    
    def compute_replacements(
        self,
        low_contrib_images: List[ImageContribution],
        high_priority_gaps: List[HybridGap],
        existing_timestamps: Set[float]
    ) -> List[FrameReplacement]:
        """
        í”„ë ˆì„ êµì²´ ê³„íš ìƒì„±
        
        Args:
            low_contrib_images: ê¸°ì—¬ë„ ë‚®ì€ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
            high_priority_gaps: Priority ë†’ì€ gap ë¦¬ìŠ¤íŠ¸
            existing_timestamps: í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ timestamp ì§‘í•©
            
        Returns:
            FrameReplacement ë¦¬ìŠ¤íŠ¸
        """
        replacements = []
        used_gaps = set()
        
        for img in low_contrib_images:
            # ì•„ì§ ì‚¬ìš©í•˜ì§€ ì•Šì€ gap ì¤‘ ê°€ì¥ ë†’ì€ priority ì„ íƒ
            best_gap = None
            for gap in high_priority_gaps:
                gap_key = (gap.start_timestamp, gap.end_timestamp)
                if gap_key not in used_gaps:
                    best_gap = gap
                    break
            
            if best_gap is None:
                continue
            
            # Gap ì¤‘ê°„ ì§€ì ìœ¼ë¡œ ìƒˆ timestamp ê²°ì •
            new_ts = self._snap_to_video_frame(best_gap.midpoint_timestamp)
            
            # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” timestampë©´ ì•½ê°„ ì¡°ì •
            while new_ts in existing_timestamps:
                new_ts = self._snap_to_video_frame(new_ts + 1/self.video_fps)
            
            replacement = FrameReplacement(
                remove_timestamp=img.timestamp,
                remove_image_name=img.image_name,
                remove_contribution=img.contribution_score,
                new_timestamp=new_ts,
                target_gap=best_gap,
                reason=self._generate_reason(img, best_gap)
            )
            
            replacements.append(replacement)
            used_gaps.add((best_gap.start_timestamp, best_gap.end_timestamp))
            existing_timestamps.add(new_ts)
            existing_timestamps.discard(img.timestamp)
        
        return replacements
    
    def _snap_to_video_frame(self, timestamp: float) -> float:
        """ë¹„ë””ì˜¤ fpsì— ë§ëŠ” ê°€ì¥ ê°€ê¹Œìš´ timestampë¡œ ìŠ¤ëƒ…"""
        frame_interval = 1.0 / self.video_fps
        frame_number = round(timestamp / frame_interval)
        return frame_number * frame_interval
    
    def _generate_reason(
        self,
        img: ImageContribution,
        gap: HybridGap
    ) -> str:
        """êµì²´ ê·¼ê±° ë¬¸ìì—´ ìƒì„±"""
        return (
            f"Low contribution ({img.contribution_score:.0f} points) â†’ "
            f"High priority gap (geo={gap.geometry_score:.3f}, "
            f"cont={gap.continuity_score:.3f}, "
            f"priority={gap.gap_priority:.3f})"
        )
    
    def generate_final_timestamps(
        self,
        original_timestamps: List[float],
        replacements: List[FrameReplacement]
    ) -> List[float]:
        """
        ìµœì¢… timestamp ë¦¬ìŠ¤íŠ¸ ìƒì„±
        
        Args:
            original_timestamps: ì›ë³¸ timestamp ë¦¬ìŠ¤íŠ¸
            replacements: êµì²´ ì •ë³´ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            êµì²´ê°€ ë°˜ì˜ëœ ìµœì¢… timestamp ë¦¬ìŠ¤íŠ¸
        """
        # ì œê±°í•  timestamp
        remove_set = {r.remove_timestamp for r in replacements}
        
        # ìœ ì§€í•  timestamp
        keep_timestamps = [ts for ts in original_timestamps if ts not in remove_set]
        
        # ì¶”ê°€í•  timestamp
        add_timestamps = [r.new_timestamp for r in replacements]
        
        # í•©ì¹˜ê³  ì •ë ¬
        final_timestamps = sorted(set(keep_timestamps + add_timestamps))
        
        return final_timestamps
    
    def print_replacement_report(self, replacements: List[FrameReplacement]) -> None:
        """êµì²´ ë³´ê³ ì„œ ì¶œë ¥"""
        print("\n" + "="*70)
        print("FRAME REPLACEMENT REPORT")
        print("="*70)
        
        for i, r in enumerate(replacements):
            print(f"\n[{i+1}] {r.remove_image_name}")
            print(f"    Remove: t={r.remove_timestamp:.3f}s (contribution={r.remove_contribution:.0f})")
            print(f"    Add:    t={r.new_timestamp:.3f}s")
            print(f"    Gap:    [{r.target_gap.start_timestamp:.3f}s ~ {r.target_gap.end_timestamp:.3f}s]")
            print(f"    Reason: {r.reason}")
        
        print("\n" + "="*70)
        print(f"Total replacements: {len(replacements)}")
        print("="*70)
```

---

### 4. í†µí•© íŒŒì´í”„ë¼ì¸

**íŒŒì¼**: `hybrid_pipeline.py` (ì‹ ê·œ ìƒì„±)

```python
"""
Hybrid Adaptive Sampling Pipeline

SfM í’ˆì§ˆ ê¸°ë°˜ Hybrid ì ‘ê·¼ë²•ì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸
"""

import logging
from pathlib import Path
from typing import List, Dict, Optional
import json

from colmap_parser import COLMAPParser
from trajectory_analyzer import TrajectoryAnalyzer
from sfm_quality_analyzer import SfMQualityAnalyzer
from hybrid_gap_analyzer import HybridGapAnalyzer
from frame_replacer import FrameReplacer
from frame_extractor import FrameExtractor

logger = logging.getLogger(__name__)


class HybridAdaptivePipeline:
    """SfM Quality ê¸°ë°˜ Hybrid Adaptive Sampling íŒŒì´í”„ë¼ì¸"""
    
    def __init__(
        self,
        video_path: str,
        output_dir: str,
        colmap_dir: str,
        video_fps: float = 30.0,
        extraction_fps: float = 2.0,
        replacement_ratio: float = 0.2,
        geometry_weight: float = 0.5,
        continuity_weight: float = 0.5,
        min_features_threshold: int = 50
    ):
        """
        Args:
            video_path: ì›ë³¸ ë¹„ë””ì˜¤ ê²½ë¡œ
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
            colmap_dir: Pass 1 COLMAP ê²°ê³¼ ë””ë ‰í† ë¦¬ (sparse/0/)
            video_fps: ì›ë³¸ ë¹„ë””ì˜¤ fps
            extraction_fps: í”„ë ˆì„ ì¶”ì¶œ fps
            replacement_ratio: êµì²´í•  í”„ë ˆì„ ë¹„ìœ¨ (0.2 = í•˜ìœ„ 20%)
            geometry_weight: Hybrid scoreì—ì„œ geometry ê°€ì¤‘ì¹˜
            continuity_weight: Hybrid scoreì—ì„œ continuity ê°€ì¤‘ì¹˜
            min_features_threshold: Textureless íŒë‹¨ ì„ê³„ê°’
        """
        self.video_path = Path(video_path)
        self.output_dir = Path(output_dir)
        self.colmap_dir = Path(colmap_dir)
        self.video_fps = video_fps
        self.extraction_fps = extraction_fps
        self.replacement_ratio = replacement_ratio
        self.geometry_weight = geometry_weight
        self.continuity_weight = continuity_weight
        self.min_features_threshold = min_features_threshold
        
        # ë¶„ì„ê¸° ì´ˆê¸°í™”
        self.sfm_analyzer = SfMQualityAnalyzer(str(colmap_dir))
        self.trajectory_analyzer = TrajectoryAnalyzer(alpha=0.7, beta=0.3, normalize=True)
        self.gap_analyzer = HybridGapAnalyzer(geometry_weight, continuity_weight)
        self.frame_replacer = FrameReplacer(video_fps)
        
    def run(self) -> Dict:
        """
        ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Returns:
            ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        logger.info("="*60)
        logger.info("HYBRID ADAPTIVE SAMPLING PIPELINE")
        logger.info("="*60)
        
        # Phase 1: SfM í’ˆì§ˆ ë¶„ì„
        logger.info("\n[Phase 1] Analyzing SfM Quality...")
        contributions = self.sfm_analyzer.parse_images_with_observations()
        continuities = self.sfm_analyzer.compute_feature_track_continuity(contributions)
        
        contrib_stats = self.sfm_analyzer.get_statistics(contributions)
        logger.info(f"  Images analyzed: {contrib_stats['num_images']}")
        logger.info(f"  Contribution mean: {contrib_stats['contribution']['mean']:.1f}")
        logger.info(f"  Contribution std: {contrib_stats['contribution']['std']:.1f}")
        
        # Phase 2: Geometry ë¶„ì„ (ê¸°ì¡´ trajectory analyzer í™œìš©)
        logger.info("\n[Phase 2] Analyzing Camera Trajectory...")
        colmap_parser = COLMAPParser(str(self.colmap_dir))
        poses = colmap_parser.parse_and_extract(fps=self.extraction_fps)
        segments = self.trajectory_analyzer.analyze_trajectory(poses)
        
        traj_stats = self.trajectory_analyzer.get_statistics(segments)
        logger.info(f"  Segments: {traj_stats['num_segments']}")
        logger.info(f"  Translation mean: {traj_stats['translation']['mean']:.3f}m")
        
        # Phase 3: Hybrid Gap ë¶„ì„
        logger.info("\n[Phase 3] Computing Hybrid Gap Priority...")
        hybrid_gaps = self.gap_analyzer.compute_hybrid_gaps(segments, continuities)
        
        # Textureless êµ¬ê°„ í•„í„°ë§
        filtered_gaps = self.gap_analyzer.filter_textureless_gaps(
            hybrid_gaps, 
            self.min_features_threshold
        )
        logger.info(f"  Total gaps: {len(hybrid_gaps)}")
        logger.info(f"  After textureless filtering: {len(filtered_gaps)}")
        
        gap_stats = self.gap_analyzer.get_statistics(filtered_gaps)
        logger.info(f"  Priority range: [{gap_stats['priority']['min']:.3f}, {gap_stats['priority']['max']:.3f}]")
        
        # Phase 4: ê¸°ì—¬ë„ ë‚®ì€ ì´ë¯¸ì§€ ì„ íƒ
        logger.info("\n[Phase 4] Selecting Low Contribution Images...")
        low_contrib_images = self.sfm_analyzer.select_low_contribution_images(
            contributions,
            bottom_ratio=self.replacement_ratio
        )
        logger.info(f"  Selected for replacement: {len(low_contrib_images)}")
        
        # Phase 5: High priority gaps ì„ íƒ
        logger.info("\n[Phase 5] Selecting High Priority Gaps...")
        high_priority_gaps = self.gap_analyzer.select_high_priority_gaps(
            filtered_gaps,
            top_k=len(low_contrib_images)
        )
        logger.info(f"  High priority gaps: {len(high_priority_gaps)}")
        
        # Phase 6: í”„ë ˆì„ êµì²´ ê³„íš
        logger.info("\n[Phase 6] Computing Frame Replacements...")
        original_timestamps = sorted([c.timestamp for c in contributions.values()])
        existing_timestamps = set(original_timestamps)
        
        replacements = self.frame_replacer.compute_replacements(
            low_contrib_images,
            high_priority_gaps,
            existing_timestamps
        )
        logger.info(f"  Planned replacements: {len(replacements)}")
        
        # êµì²´ ë³´ê³ ì„œ ì¶œë ¥
        self.frame_replacer.print_replacement_report(replacements)
        
        # Phase 7: ìµœì¢… timestamp ë¦¬ìŠ¤íŠ¸ ìƒì„±
        logger.info("\n[Phase 7] Generating Final Timestamps...")
        final_timestamps = self.frame_replacer.generate_final_timestamps(
            original_timestamps,
            replacements
        )
        logger.info(f"  Original frames: {len(original_timestamps)}")
        logger.info(f"  Final frames: {len(final_timestamps)}")
        
        # ê²°ê³¼ ì €ì¥
        result = {
            'config': {
                'video_path': str(self.video_path),
                'colmap_dir': str(self.colmap_dir),
                'replacement_ratio': self.replacement_ratio,
                'geometry_weight': self.geometry_weight,
                'continuity_weight': self.continuity_weight,
                'min_features_threshold': self.min_features_threshold,
            },
            'statistics': {
                'contribution': contrib_stats,
                'trajectory': traj_stats,
                'gap': gap_stats,
            },
            'replacements': [
                {
                    'remove_timestamp': r.remove_timestamp,
                    'remove_image_name': r.remove_image_name,
                    'remove_contribution': r.remove_contribution,
                    'new_timestamp': r.new_timestamp,
                    'reason': r.reason,
                }
                for r in replacements
            ],
            'final_timestamps': final_timestamps,
            'frame_count': {
                'original': len(original_timestamps),
                'final': len(final_timestamps),
                'replaced': len(replacements),
            }
        }
        
        # JSON ì €ì¥
        result_path = self.output_dir / "hybrid_sampling_result.json"
        with open(result_path, 'w') as f:
            json.dump(result, f, indent=2)
        logger.info(f"\nResults saved to: {result_path}")
        
        return result


if __name__ == "__main__":
    import sys
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # ì‚¬ìš© ì˜ˆì‹œ
    pipeline = HybridAdaptivePipeline(
        video_path="/path/to/video.mp4",
        output_dir="/path/to/output",
        colmap_dir="/path/to/pass1/sparse/0",
        video_fps=30.0,
        extraction_fps=2.0,
        replacement_ratio=0.2,
        geometry_weight=0.5,
        continuity_weight=0.5,
    )
    
    result = pipeline.run()
    print(f"\nFinal frame count: {result['frame_count']['final']}")
```

---

## íŒŒì¼ êµ¬ì¡°

```
adaptive_sampling/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ colmap_parser.py          # ê¸°ì¡´ (ìˆ˜ì • ì—†ìŒ)
â”œâ”€â”€ trajectory_analyzer.py     # ê¸°ì¡´ (ìˆ˜ì • ì—†ìŒ)
â”œâ”€â”€ adaptive_sampler.py        # ê¸°ì¡´ (ìˆ˜ì • ì—†ìŒ)
â”œâ”€â”€ frame_extractor.py         # ê¸°ì¡´ (ìˆ˜ì • ì—†ìŒ)
â”œâ”€â”€ pipeline.py                # ê¸°ì¡´ geometry ê¸°ë°˜ íŒŒì´í”„ë¼ì¸
â”‚
â”œâ”€â”€ sfm_quality_analyzer.py    # ğŸ†• SfM ê¸°ì—¬ë„ ë¶„ì„
â”œâ”€â”€ hybrid_gap_analyzer.py     # ğŸ†• Hybrid Gap Priority ê³„ì‚°
â”œâ”€â”€ frame_replacer.py          # ğŸ†• í”„ë ˆì„ êµì²´ ë¡œì§
â””â”€â”€ hybrid_pipeline.py         # ğŸ†• í†µí•© Hybrid íŒŒì´í”„ë¼ì¸
```

---

## ì‹¤í–‰ ë°©ë²•

### Step 1: Pass 1 ì‹¤í–‰ (ê¸°ì¡´ ë°©ì‹)
```bash
# Uniform fps=2ë¡œ í”„ë ˆì„ ì¶”ì¶œ ë° COLMAP ì‹¤í–‰
python pipeline.py \
    --video /path/to/video.mp4 \
    --output ./data/experiment/pass1 \
    --fps 2.0
```

### Step 2: Hybrid Pass 2 ì‹¤í–‰ (ìƒˆ ë°©ì‹)
```bash
# SfM í’ˆì§ˆ ê¸°ë°˜ í”„ë ˆì„ êµì²´
python hybrid_pipeline.py \
    --video /path/to/video.mp4 \
    --colmap ./data/experiment/pass1/sparse/0 \
    --output ./data/experiment/pass2_hybrid \
    --replacement-ratio 0.2 \
    --geometry-weight 0.5 \
    --continuity-weight 0.5
```

### Step 3: ê²°ê³¼ ë¹„êµ
```bash
# Pass 1 vs Pass 2 SfM points ë¹„êµ
echo "Pass 1 SfM points:"
grep "Number of 3D points" ./data/experiment/pass1/colmap.log

echo "Pass 2 (Hybrid) SfM points:"
grep "Number of 3D points" ./data/experiment/pass2_hybrid/colmap.log
```

---

## ì˜ˆìƒ ê²°ê³¼

### ì‹œë‚˜ë¦¬ì˜¤ A: ì •ìƒì ì¸ ì˜ìƒ

```
Pass 1 (Uniform):
  - 240 frames
  - 18,200 SfM points
  - PSNR: 30.81

Pass 2 (Hybrid):
  - 240 frames (ë™ì¼)
  - 19,500+ SfM points (ì¦ê°€ ì˜ˆìƒ)
  - PSNR: 31.xx (ê°œì„  ì˜ˆìƒ)

ì´ìœ :
  - ê¸°ì—¬ë„ ë‚®ì€ í”„ë ˆì„ â†’ ë†’ì€ priority gapìœ¼ë¡œ ì´ë™
  - Feature matching ì„±ê³µë¥  ì¦ê°€
  - SfM point í’ˆì§ˆ í–¥ìƒ
```

### ì‹œë‚˜ë¦¬ì˜¤ B: Textureless ì˜ì—­ì´ ë§ì€ ì˜ìƒ

```
ê¸°ì¡´ Feature Trackë§Œ ì‚¬ìš© ì‹œ:
  - Textureless êµ¬ê°„ì— í”„ë ˆì„ ì¶”ê°€ â†’ íš¨ê³¼ ì—†ìŒ
  - ì˜¤íˆë ¤ ë‹¤ë¥¸ êµ¬ê°„ í”„ë ˆì„ ë‚­ë¹„

Hybrid ì‚¬ìš© ì‹œ:
  - Textureless êµ¬ê°„ ìë™ í•„í„°ë§ (min_features_threshold)
  - ì‹¤ì œ ê°œì„  ê°€ëŠ¥í•œ êµ¬ê°„ì—ë§Œ í”„ë ˆì„ ë°°ì¹˜
```

---

## í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°€ì´ë“œ

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ì„¤ëª… | ì¡°ì • ê°€ì´ë“œ |
|----------|--------|------|-------------|
| `replacement_ratio` | 0.2 | êµì²´í•  í”„ë ˆì„ ë¹„ìœ¨ | 0.1~0.3 ê¶Œì¥ |
| `geometry_weight` | 0.5 | Geometry ê°€ì¤‘ì¹˜ | ë¹ ë¥¸ ì›€ì§ì„ ë§ìœ¼ë©´ â†‘ |
| `continuity_weight` | 0.5 | Continuity ê°€ì¤‘ì¹˜ | Feature ëŠê¹€ ë§ìœ¼ë©´ â†‘ |
| `min_features_threshold` | 50 | Textureless ì„ê³„ê°’ | ë°ì´í„°ì…‹ì— ë”°ë¼ ì¡°ì • |

---

## Contribution 2ë¥¼ ìœ„í•œ í™•ì¥ (ì¶”í›„ êµ¬í˜„)

### ì„ íƒì  í”„ë ˆì„ ì¶”ê°€

```python
def selective_frame_addition(
    base_timestamps: List[float],
    gaps: List[HybridGap],
    max_additional: int
) -> List[float]:
    """
    fps ì¦ê°€ ì—†ì´ ì„ íƒì ìœ¼ë¡œ í”„ë ˆì„ ì¶”ê°€
    
    ëª©í‘œ: fps=3 ì „ì²´ ì¶”ê°€ë³´ë‹¤ ì ì€ í”„ë ˆì„ìœ¼ë¡œ ë™ë“±/ìš°ìˆ˜ ì„±ëŠ¥
    
    Args:
        base_timestamps: ê¸°ë³¸ timestamp (fps=2)
        gaps: Priority ì •ë ¬ëœ gap ë¦¬ìŠ¤íŠ¸
        max_additional: ìµœëŒ€ ì¶”ê°€ í”„ë ˆì„ ìˆ˜
        
    Returns:
        í™•ì¥ëœ timestamp ë¦¬ìŠ¤íŠ¸
    """
    additional = []
    
    for gap in gaps[:max_additional]:
        new_ts = gap.midpoint_timestamp
        if new_ts not in base_timestamps:
            additional.append(new_ts)
    
    return sorted(base_timestamps + additional)
```

### ì‹¤í—˜ ì„¤ê³„

```
Baseline A: fps=2 (Nì¥)           â†’ SfM points X, PSNR P1
Baseline B: fps=3 (1.5Nì¥)        â†’ SfM points Y, PSNR P2

Proposed:   fps=2 + Mì¥ ì¶”ê°€      â†’ SfM points Z, PSNR P3
            (M << 0.5N, ì˜ˆ: 0.2N)

ì„±ê³µ ì¡°ê±´: Z â‰¥ Y and P3 â‰¥ P2 with (N+M) < 1.5N
```

---

## ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] `sfm_quality_analyzer.py` êµ¬í˜„
- [ ] `hybrid_gap_analyzer.py` êµ¬í˜„  
- [ ] `frame_replacer.py` êµ¬í˜„
- [ ] `hybrid_pipeline.py` êµ¬í˜„
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] Museum_cut ë°ì´í„°ë¡œ Pass 1 ì‹¤í–‰
- [ ] Hybrid Pass 2 ì‹¤í–‰
- [ ] SfM points ë¹„êµ ë¶„ì„
- [ ] 3DGS í•™ìŠµ ë° PSNR í‰ê°€
- [ ] Contribution 2ë¥¼ ìœ„í•œ ì„ íƒì  ì¶”ê°€ ì‹¤í—˜

---

## ì°¸ê³  ìë£Œ

- [COLMAP Output Format](https://colmap.github.io/format.html)
- [3D Gaussian Splatting Paper](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/)
- ê¸°ì¡´ êµ¬í˜„: `CLAUDE.md`, `adaptive_sampler.py`, `trajectory_analyzer.py`

